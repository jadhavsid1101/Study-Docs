Sqoop Learningss
************************************Connectivity************************************
1) List Databases(To check connectivity)
sqoop list-databases \
--connect jdbc:mysql://172.21.154.225:3306 \
--username root \
--password cloudera

2) List tables
sqoop list-tables \
--connect jdbc:mysql://172.21.154.225:3306/retail_db \
--username root \
--password cloudera
************************************Table Level Import************************************
3) Import

a) Basic Import Single Table

sqoop import \
--connect jdbc:mysql://172.21.154.225:3306/retail_db \
--table orders \
--username root \
--password cloudera

b) Import table with specific columns

sqoop import \
--connect jdbc:mysql://172.21.154.225:3306/retail_db \
--username root \
--password cloudera \
--table orders \
--columns "order_id,order_date"

c) Controlling the import parallelism 

sqoop import \
--connect jdbc:mysql://172.21.154.225:3306/retail_db \
--username root \
--password cloudera \
--table orders \
-m 8

OR

sqoop import \
--connect jdbc:mysql://172.21.154.225:3306/retail_db \
--username root \
--password cloudera \
--table orders \
--num-mappers 8

---Comments----Check the input folder there will be 8 part of files

d) Specify File format
sqoop supports 4 formats
1. text (default)--as-textfile
2. sequence files--as-sequencefile
3. parquet files--as-parquetfile \
4. avrodata files--as-avrodatafile

sqoop import \
--connect jdbc:mysql://172.21.154.225:3306/retail_db \
--username root \
--password cloudera \
--table orders \
--as-textfile

e) Managing Target Directory

By default sqoop imports the data in /user/{username}/{tableName} format.
We can change this using 
1) --target-dir <dir> : Will import data directly inside specified directory
2) --warehouse-dir <dir> : Will create sub directory inside specified directory and name of sub directory will be that of table name

a)--target-dir
sqoop import \
--connect jdbc:mysql://172.21.154.225:3306/retail_db \
--username root \
--password cloudera \
--table orders \
--target-dir /user/cloudera/sqoop-import/orders

b)--warehouse-dir
sqoop import \
--connect jdbc:mysql://172.21.154.225:3306/retail_db \
--username root \
--password cloudera \
--table orders \
--warehouse-dir /user/cloudera/sqoop-import/

f) Delete Target directory to overwrite data
sqoop import \
--connect jdbc:mysql://172.21.154.225:3306/retail_db \
--username root \
--password cloudera \
--table orders \
--delete-target-dir

g) Append data to existing file
sqoop import \
--connect jdbc:mysql://172.21.154.225:3306/retail_db \
--username root \
--password cloudera \
--table orders \
--append

h) --split-by
--Should be used when the table to be imported does not have primary key
--Sqoop uses the specified column for splitting data while importing
--split-by column must be numberic
--if split-by column is not numberic the you will have to pass additional argument 	-Dorg.apache.sqoop.splitter.allow_text_splitter=true(can be passed in sqoop.property file also)
--**Good to follow Things**--
1.Column should be indexed--For performance
2.Values in the field should be sparse--For equal partitions of mappers
3.Also it should be sequence generated or evenly incremented--For equal partitions of mappers
4.Null values will be skipped


a.Split by numeric
sqoop import \
--connect jdbc:mysql://192.168.56.101:3306/retail_db \
--username root \
--password cloudera \
--table order_items_nopk \
--split-by order_id

b.Split by varchar
sqoop import \
-Dorg.apache.sqoop.splitter.allow_text_splitter=true
--connect jdbc:mysql://192.168.56.101:3306/retail_db \
--username root \
--password cloudera \
--table orders \
--split-by order_status

i)--autoreset-to-one-mapper
--Should be used when the table to be imported does not have primary key and you do not want to use -splitby

sqoop import \
--connect jdbc:mysql://192.168.56.101:3306/retail_db \
--username root \
--password cloudera \
--table order_items_nopk \
--autoreset-to-one-mapper

j)--compress {-z} and --compression-codec <c>
-We can compress imported to save storage space
-By using --compress or -z
-Default compression algorithm is gzip
-We can use other compression algorithms by using --compression-codec property

sqoop import \
--connect jdbc:mysql://192.168.56.101:3306/retail_db \
--username root \
--password cloudera \
--table orders \
--compress

--Comments--unzip files by guzip command


k) --boundary-query
-We can use this argument to specify the splits range by specifying MIN and MAX

sqoop import \
--connect jdbc:mysql://192.168.56.101:3306/retail_db \
--username root \
--password cloudera \
--table orders \
--boundary-query 'select 1,10 from orders' \
-m 1

****Import Arguments******
Argument	Description
--append								*****DONE********
--as-avrodatafile						*****DONE********
--as-sequencefile						*****DONE********
--as-textfile							*****DONE********
--as-parquetfile						*****DONE********
--boundary-query <statement>			*****DONE********
--columns <col,col,col…>				*****DONE********
--delete-target-dir						*****DONE********
--direct								Use direct connector if exists for the database
--fetch-size <n>						Number of entries to read from database at once.
--inline-lob-limit <n>					Set the maximum size for an inline LOB
-m,--num-mappers <n>					*****DONE********
-e,--query <statement>					*****DONE--Not executed********Import the results of statement.
--split-by <column-name>				*****DONE********
--autoreset-to-one-mapper			    *****DONE********
--table <table-name>					*****DONE********
--target-dir <dir>						*****DONE********
--warehouse-dir <dir>					*****DONE********
--where <where clause>					*****DONE--Not executed********WHERE clause to use during import
-z,--compress							*****DONE********
--compression-codec <c>					*****DONE********
--null-string <null-string>				*****DONE--Not executed********
--null-non-string <null-string>			*****DONE--Not executed********

****Common Arguments****
--connect <jdbc-uri>					*****DONE********	Specify JDBC connect string
--connection-manager <class-name>		Specify connection manager class to use
--driver <class-name>					Manually specify JDBC driver class to use
--hadoop-mapred-home <dir>				Override $HADOOP_MAPRED_HOME
--help									*****DONE********	Print usage instructions
--password-file							Set path for a file containing the authentication password
-P										Read password from console
--password <password>					*****DONE********	Set authentication password
--username <username>					*****DONE********	Set authentication username
--verbose								Print more information while working
--connection-param-file <filename>		Optional properties file that provides connection parameters
--relaxed-isolation						Set connection transaction isolation to read uncommitted for the mappers.

****Incremental import arguments****
--check-column (col)	Specifies the column to be examined when determining which rows to import.
--incremental (mode)	Specifies how Sqoop determines which rows are new. Legal values for mode include append and lastmodified.
--last-value (value)	Specifies the maximum value of the check column from the previous import.

****Changing separators****((((((Try later-------------IMP))))))
--enclosed-by <char>	Sets a required field enclosing character
--escaped-by <char>	Sets the escape character
--fields-terminated-by <char>	Sets the field separator character
--lines-terminated-by <char>	Sets the end-of-line character
--mysql-delimiters	Uses MySQL’s default delimiter set: fields: , lines: \n escaped-by: \ optionally-enclosed-by: '
--optionally-enclosed-by <char>	Sets a field enclosing character


************************************Hive Import************************************
1) Basics commands
a) Connect to hive
hive

b) Create database
create database db_name;

c) Switch database
use db_name;

d) Create table
create table t(i int);

e) Insert into table
insert into table t values (1);

f) Check 
select * from t;

g) Drop
drop table t;

2) Sqoop Import hive

sqoop import \
--connect jdbc:mysql://192.168.56.101:3306/retail_db \
--username root \
--password cloudera \
--table order_items \
--hive-import \
--hive-database sid_sqoop_import \
--hive-table order_items \
--num-mappers 2

***By default mode is append***

3) Overwrite existing table
sqoop import \
--connect jdbc:mysql://192.168.56.101:3306/retail_db \
--username root \
--password cloudera \
--table order_items \
--hive-import \
--hive-database sid_sqoop_import \
--hive-table order_items \
--num-mappers 2 \
--hive-overwrite

4) Fail if target table exists
sqoop import \
--connect jdbc:mysql://192.168.56.101:3306/retail_db \
--username root \
--password cloudera \
--table order_items \
--hive-import \
--hive-database sid_sqoop_import \
--hive-table order_items \
--num-mappers 2 \
--create-hive-table